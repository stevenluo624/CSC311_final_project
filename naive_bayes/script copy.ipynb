{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8de231",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8309fc",
   "metadata": {},
   "source": [
    "## 1. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8105b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"../cleaned_data/train_clean.csv\")\n",
    "valid = pd.read_csv(\"../cleaned_data/validation_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf9924",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing\n",
    "### 2.1 Combine and clean text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b931f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text columns into a single column because Naive Bayes works on a single text input\n",
    "text_cols = [\"tasks_use_model\", \"suboptimal_example\", \"verify_method\"]\n",
    "\n",
    "def combine_text(df):\n",
    "    df[\"full_text\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "    return df\n",
    "\n",
    "train = combine_text(train)\n",
    "valid = combine_text(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing: lowercase, remove punctuation, extra spaces\n",
    "import re\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "train[\"full_text\"] = train[\"full_text\"].apply(clean_text)\n",
    "valid[\"full_text\"] = valid[\"full_text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768482d0",
   "metadata": {},
   "source": [
    "### 2.2 Select numeric and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de4d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m feature_cols = ordinal_cols + categorical_cols\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Prepare numeric feature matrices\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m train[feature_cols] = \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m valid[feature_cols] = valid[feature_cols].apply(clean_text)\n\u001b[32m     21\u001b[39m X_train_numeric = train[feature_cols].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\venni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\venni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\venni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\venni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mclean_text\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_text\u001b[39m(s):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     s = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[^a-z0-9\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     s = re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, s)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\venni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:208\u001b[39m, in \u001b[36msub\u001b[39m\u001b[34m(pattern, repl, string, count, flags, *args)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m    203\u001b[39m     warnings.warn(\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is passed as positional argument\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    206\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'Series'"
     ]
    }
   ],
   "source": [
    "# List of numeric features\n",
    "ordinal_cols = [\n",
    "    \"academic_use_likelihood\",\n",
    "    \"suboptimal_frequency\",\n",
    "    \"reference_expectation\",\n",
    "    \"verify_frequency\"\n",
    "]\n",
    "\n",
    "# List of categorical features\n",
    "categorical_cols = [c for c in train.columns\n",
    "                    if c.startswith(\"best_task_types_\") \n",
    "                    or c.startswith(\"suboptimal_task_types_\")]\n",
    "\n",
    "# Combine all feature columns\n",
    "feature_cols = ordinal_cols + categorical_cols\n",
    "\n",
    "# Prepare numeric feature matrices\n",
    "X_train_numeric = train[feature_cols].values\n",
    "X_valid_numeric = valid[feature_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4f9b7",
   "metadata": {},
   "source": [
    "## 3. Vectorize text and build feature matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840c255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 3000), (123, 3000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize text data using Bag-of-Words\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_train_text = vectorizer.fit_transform(train[\"full_text\"])         # Fit on training data -> create vocabulary\n",
    "X_valid_text = vectorizer.transform(valid[\"full_text\"])             # Transform validation data -> use same vocabulary\n",
    "\n",
    "X_train_text.shape, X_valid_text.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7b665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine text and numeric features\n",
    "X_train = hstack([X_train_text, X_train_numeric])\n",
    "X_valid = hstack([X_valid_text, X_valid_numeric])\n",
    "\n",
    "# Prepare labels\n",
    "y_train = train[\"label\"].values\n",
    "y_valid = valid[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674f06c",
   "metadata": {},
   "source": [
    "## 4. Train Naive Bayes baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2e9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (alpha=1.0): 0.890625\n",
      "Validation accuracy (alpha=1.0): 0.6097560975609756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.696     0.780     0.736        41\n",
      "           1      0.556     0.610     0.581        41\n",
      "           2      0.562     0.439     0.493        41\n",
      "\n",
      "    accuracy                          0.610       123\n",
      "   macro avg      0.605     0.610     0.603       123\n",
      "weighted avg      0.605     0.610     0.603       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Simple baseline with alpha = 1.0 -> Laplace smoothing factor\n",
    "nb = MultinomialNB(alpha=1.0)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = nb.predict(X_train)\n",
    "y_valid_pred = nb.predict(X_valid)\n",
    "\n",
    "print(\"Training accuracy (alpha=1.0):\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Validation accuracy (alpha=1.0):\", accuracy_score(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c865f3b",
   "metadata": {},
   "source": [
    "## 5. With vs without stopwords\n",
    "### 5.1 Compare Bag-of-Words with vs without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e5fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== stop_words = False ===\n",
      "acc=0.5691, stopwords=False, mf=1000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5772, stopwords=False, mf=1000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=1000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=1000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5610, stopwords=False, mf=1000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5854, stopwords=False, mf=1000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.6016, stopwords=False, mf=1000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6341, stopwords=False, mf=1000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5528, stopwords=False, mf=1000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5854, stopwords=False, mf=1000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=1000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=1000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.5854, stopwords=False, mf=1000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.5854, stopwords=False, mf=1000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.5935, stopwords=False, mf=1000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=1000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=1000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=1000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=False, mf=1000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=1000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5935, stopwords=False, mf=1000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=False, mf=1000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.5935, stopwords=False, mf=1000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=1000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.6098, stopwords=False, mf=1000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.6260, stopwords=False, mf=1000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.6423, stopwords=False, mf=1000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6667, stopwords=False, mf=1000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.6179, stopwords=False, mf=1000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.6179, stopwords=False, mf=1000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.6423, stopwords=False, mf=1000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=1000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.6260, stopwords=False, mf=1000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.6260, stopwords=False, mf=1000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6504, stopwords=False, mf=1000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=1000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5285, stopwords=False, mf=2000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5528, stopwords=False, mf=2000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5610, stopwords=False, mf=2000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=2000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5285, stopwords=False, mf=2000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=False, mf=2000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5691, stopwords=False, mf=2000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=2000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5447, stopwords=False, mf=2000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5447, stopwords=False, mf=2000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=False, mf=2000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=False, mf=2000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.5935, stopwords=False, mf=2000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6341, stopwords=False, mf=2000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5935, stopwords=False, mf=2000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.6260, stopwords=False, mf=2000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6179, stopwords=False, mf=2000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=2000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5935, stopwords=False, mf=2000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.6179, stopwords=False, mf=2000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=2000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=2000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=2000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=2000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=2000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=2000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=2000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=2000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6504, stopwords=False, mf=2000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5285, stopwords=False, mf=3000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5528, stopwords=False, mf=3000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5854, stopwords=False, mf=3000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=3000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5285, stopwords=False, mf=3000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=False, mf=3000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5691, stopwords=False, mf=3000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=3000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5447, stopwords=False, mf=3000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5447, stopwords=False, mf=3000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=False, mf=3000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=False, mf=3000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.6179, stopwords=False, mf=3000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.6179, stopwords=False, mf=3000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.6098, stopwords=False, mf=3000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=3000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=False, mf=3000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.5691, stopwords=False, mf=3000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.5935, stopwords=False, mf=3000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.6016, stopwords=False, mf=3000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=3000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.5935, stopwords=False, mf=3000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.6098, stopwords=False, mf=3000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6179, stopwords=False, mf=3000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6179, stopwords=False, mf=3000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5203, stopwords=False, mf=5000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5528, stopwords=False, mf=5000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5854, stopwords=False, mf=5000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5285, stopwords=False, mf=5000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=False, mf=5000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5691, stopwords=False, mf=5000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=5000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5447, stopwords=False, mf=5000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5447, stopwords=False, mf=5000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=False, mf=5000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.6016, stopwords=False, mf=5000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.6260, stopwords=False, mf=5000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=5000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5772, stopwords=False, mf=5000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=False, mf=5000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6179, stopwords=False, mf=5000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=False, mf=5000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=False, mf=5000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6423, stopwords=False, mf=5000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.5772, stopwords=False, mf=5000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.6179, stopwords=False, mf=5000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.5935, stopwords=False, mf=5000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.5691, stopwords=False, mf=5000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.6423, stopwords=False, mf=5000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6098, stopwords=False, mf=5000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.5854, stopwords=False, mf=5000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=False, mf=5000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6260, stopwords=False, mf=5000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6016, stopwords=False, mf=5000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "\n",
      "=== stop_words = True ===\n",
      "acc=0.5528, stopwords=True, mf=1000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=1000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=1000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=1000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5366, stopwords=True, mf=1000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5691, stopwords=True, mf=1000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5772, stopwords=True, mf=1000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6016, stopwords=True, mf=1000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=1000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5691, stopwords=True, mf=1000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5772, stopwords=True, mf=1000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=1000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.5854, stopwords=True, mf=1000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=1000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=1000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=1000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5772, stopwords=True, mf=1000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=1000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.5772, stopwords=True, mf=1000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.5854, stopwords=True, mf=1000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.6016, stopwords=True, mf=1000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=1000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=1000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.6016, stopwords=True, mf=1000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.6016, stopwords=True, mf=1000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6016, stopwords=True, mf=1000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=1000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5366, stopwords=True, mf=2000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5447, stopwords=True, mf=2000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=2000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=2000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=2000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=2000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=2000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=2000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=2000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=True, mf=2000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.5935, stopwords=True, mf=2000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=2000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.6179, stopwords=True, mf=2000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6260, stopwords=True, mf=2000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=2000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.5447, stopwords=True, mf=2000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.5691, stopwords=True, mf=2000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6016, stopwords=True, mf=2000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=2000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.5447, stopwords=True, mf=2000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.5691, stopwords=True, mf=2000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.5854, stopwords=True, mf=2000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.6016, stopwords=True, mf=2000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6098, stopwords=True, mf=2000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6341, stopwords=True, mf=2000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5366, stopwords=True, mf=3000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5447, stopwords=True, mf=3000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5610, stopwords=True, mf=3000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=3000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=3000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=3000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=3000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=3000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=3000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=3000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=3000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=3000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=3000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.6016, stopwords=True, mf=3000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.6016, stopwords=True, mf=3000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=3000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=3000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.5854, stopwords=True, mf=3000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6016, stopwords=True, mf=3000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=3000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=3000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.6179, stopwords=True, mf=3000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6260, stopwords=True, mf=3000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=3000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.5528, stopwords=True, mf=3000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.5772, stopwords=True, mf=3000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.5691, stopwords=True, mf=3000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=3000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=3000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=3000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=3000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=3000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=3000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=3000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6179, stopwords=True, mf=3000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=3000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "acc=0.5366, stopwords=True, mf=5000, ngram=(1, 1), min_df=1, alpha=0.1\n",
      "acc=0.5447, stopwords=True, mf=5000, ngram=(1, 1), min_df=1, alpha=0.5\n",
      "acc=0.5610, stopwords=True, mf=5000, ngram=(1, 1), min_df=1, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=5000, ngram=(1, 1), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=5000, ngram=(1, 1), min_df=2, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=5000, ngram=(1, 1), min_df=2, alpha=0.5\n",
      "acc=0.5935, stopwords=True, mf=5000, ngram=(1, 1), min_df=2, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=5000, ngram=(1, 1), min_df=2, alpha=2.0\n",
      "acc=0.5610, stopwords=True, mf=5000, ngram=(1, 1), min_df=3, alpha=0.1\n",
      "acc=0.5610, stopwords=True, mf=5000, ngram=(1, 1), min_df=3, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=5000, ngram=(1, 1), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=5000, ngram=(1, 1), min_df=3, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=5000, ngram=(1, 2), min_df=1, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=5000, ngram=(1, 2), min_df=1, alpha=0.5\n",
      "acc=0.5854, stopwords=True, mf=5000, ngram=(1, 2), min_df=1, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=5000, ngram=(1, 2), min_df=1, alpha=2.0\n",
      "acc=0.5528, stopwords=True, mf=5000, ngram=(1, 2), min_df=2, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=5000, ngram=(1, 2), min_df=2, alpha=0.5\n",
      "acc=0.6098, stopwords=True, mf=5000, ngram=(1, 2), min_df=2, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=5000, ngram=(1, 2), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=5000, ngram=(1, 2), min_df=3, alpha=0.1\n",
      "acc=0.6179, stopwords=True, mf=5000, ngram=(1, 2), min_df=3, alpha=0.5\n",
      "acc=0.6260, stopwords=True, mf=5000, ngram=(1, 2), min_df=3, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=5000, ngram=(1, 2), min_df=3, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=5000, ngram=(1, 3), min_df=1, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=5000, ngram=(1, 3), min_df=1, alpha=0.5\n",
      "acc=0.6016, stopwords=True, mf=5000, ngram=(1, 3), min_df=1, alpha=1.0\n",
      "acc=0.6098, stopwords=True, mf=5000, ngram=(1, 3), min_df=1, alpha=2.0\n",
      "acc=0.5447, stopwords=True, mf=5000, ngram=(1, 3), min_df=2, alpha=0.1\n",
      "acc=0.6016, stopwords=True, mf=5000, ngram=(1, 3), min_df=2, alpha=0.5\n",
      "acc=0.6016, stopwords=True, mf=5000, ngram=(1, 3), min_df=2, alpha=1.0\n",
      "acc=0.6179, stopwords=True, mf=5000, ngram=(1, 3), min_df=2, alpha=2.0\n",
      "acc=0.5691, stopwords=True, mf=5000, ngram=(1, 3), min_df=3, alpha=0.1\n",
      "acc=0.5935, stopwords=True, mf=5000, ngram=(1, 3), min_df=3, alpha=0.5\n",
      "acc=0.6179, stopwords=True, mf=5000, ngram=(1, 3), min_df=3, alpha=1.0\n",
      "acc=0.6260, stopwords=True, mf=5000, ngram=(1, 3), min_df=3, alpha=2.0\n",
      "\n",
      "Best validation accuracy: 0.6666666666666666\n",
      "Best config: {'stopwords': False, 'max_features': 1000, 'ngram_range': (1, 3), 'min_df': 1, 'alpha': 2.0, 'vectorizer': CountVectorizer(max_features=1000, ngram_range=(1, 3))}\n"
     ]
    }
   ],
   "source": [
    "stopword_options = [False, True]\n",
    "max_features_list = [1000, 2000, 3000, 5000]\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "min_dfs = [1, 2, 3]\n",
    "alphas = [0.1, 0.5, 1.0, 2.0]\n",
    "\n",
    "best_acc = -np.inf\n",
    "best_config = None\n",
    "\n",
    "for use_stopwords in stopword_options:\n",
    "    print(f\"\\n=== stop_words = {use_stopwords} ===\")\n",
    "    \n",
    "    for mf in max_features_list:\n",
    "        for ngram in ngram_ranges:\n",
    "            for md in min_dfs:\n",
    "                # Build vectorizer for this config\n",
    "                if use_stopwords:\n",
    "                    vectorizer = CountVectorizer(\n",
    "                        max_features=mf,\n",
    "                        ngram_range=ngram,\n",
    "                        min_df=md,\n",
    "                        stop_words='english'\n",
    "                    )\n",
    "                else:\n",
    "                    vectorizer = CountVectorizer(\n",
    "                        max_features=mf,\n",
    "                        ngram_range=ngram,\n",
    "                        min_df=md\n",
    "                    )\n",
    "                \n",
    "                # Fit on train text, transform train + valid\n",
    "                X_train_text = vectorizer.fit_transform(train[\"full_text\"])\n",
    "                X_valid_text = vectorizer.transform(valid[\"full_text\"])\n",
    "                \n",
    "                # Combine with numeric features\n",
    "                X_train_tmp = hstack([X_train_text, X_train_numeric])\n",
    "                X_valid_tmp = hstack([X_valid_text, X_valid_numeric])\n",
    "                \n",
    "                for alpha in alphas:\n",
    "                    nb = MultinomialNB(alpha=alpha)\n",
    "                    nb.fit(X_train_tmp, y_train)\n",
    "                    y_pred = nb.predict(X_valid_tmp)\n",
    "                    \n",
    "                    acc = accuracy_score(y_valid, y_pred)\n",
    "                    print(\n",
    "                        f\"acc={acc:.4f}, stopwords={use_stopwords}, \"\n",
    "                        f\"mf={mf}, ngram={ngram}, min_df={md}, alpha={alpha}\"\n",
    "                    )\n",
    "                    \n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_config = {\n",
    "                            \"stopwords\": use_stopwords,\n",
    "                            \"max_features\": mf,\n",
    "                            \"ngram_range\": ngram,\n",
    "                            \"min_df\": md,\n",
    "                            \"alpha\": alpha,\n",
    "                            \"vectorizer\": vectorizer,  # keep the fitted one\n",
    "                        }\n",
    "\n",
    "print(\"\\nBest validation accuracy:\", best_acc)\n",
    "print(\"Best config:\", best_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc772693",
   "metadata": {},
   "source": [
    "### 5.2 Rebuild features and final model using best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b831706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best config:\n",
      " stopwords: False\n",
      " max_features: 1000\n",
      " ngram_range: (1, 3)\n",
      " min_df: 1\n",
      " alpha: 2.0\n",
      "Final validation accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.761     0.854     0.805        41\n",
      "           1      0.615     0.585     0.600        41\n",
      "           2      0.605     0.561     0.582        41\n",
      "\n",
      "    accuracy                          0.667       123\n",
      "   macro avg      0.661     0.667     0.662       123\n",
      "weighted avg      0.661     0.667     0.662       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_use_stopwords = best_config[\"stopwords\"]\n",
    "best_mf = best_config[\"max_features\"]\n",
    "best_ngram = best_config[\"ngram_range\"]\n",
    "best_min_df = best_config[\"min_df\"]\n",
    "best_alpha = best_config[\"alpha\"]\n",
    "\n",
    "print(\"Using best config:\")\n",
    "print(\" stopwords:\", best_use_stopwords)\n",
    "print(\" max_features:\", best_mf)\n",
    "print(\" ngram_range:\", best_ngram)\n",
    "print(\" min_df:\", best_min_df)\n",
    "print(\" alpha:\", best_alpha)\n",
    "\n",
    "# Recreate & refit vectorizer cleanly (optional; or reuse best_config['vectorizer'])\n",
    "if best_use_stopwords:\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=best_mf,\n",
    "        ngram_range=best_ngram,\n",
    "        min_df=best_min_df,\n",
    "        stop_words='english'\n",
    "    )\n",
    "else:\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=best_mf,\n",
    "        ngram_range=best_ngram,\n",
    "        min_df=best_min_df\n",
    "    )\n",
    "\n",
    "X_train_text = vectorizer.fit_transform(train[\"full_text\"])\n",
    "X_valid_text = vectorizer.transform(valid[\"full_text\"])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X_train = hstack([X_train_text, X_train_numeric])\n",
    "X_valid = hstack([X_valid_text, X_valid_numeric])\n",
    "\n",
    "final_nb = MultinomialNB(alpha=best_alpha)\n",
    "final_nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y_valid_pred = final_nb.predict(X_valid)\n",
    "print(\"Final validation accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a04bdc",
   "metadata": {},
   "source": [
    "## 6. 5-fold GroupKFold cross-validation to tune alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4420f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1, mean CV accuracy = 0.6406\n",
      "alpha = 0.5, mean CV accuracy = 0.6371\n",
      "alpha = 1.0, mean CV accuracy = 0.6424\n",
      "alpha = 2.0, mean CV accuracy = 0.6372\n",
      "Best alpha from CV: 1.0 with accuracy 0.6423751686909582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# csr_matrix format for efficient row slicing\n",
    "X_train = csr_matrix(X_train)\n",
    "\n",
    "alphas = [0.1, 0.5, 1.0, 2.0]\n",
    "groups = train[\"student_id\"].values   # group by student\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "cv_results = {}\n",
    "\n",
    "# Cross-validation to find best alpha\n",
    "for a in alphas:\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Split data into training and validation folds\n",
    "    for train_idx, val_idx in gkf.split(X_train, y_train, groups=groups):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Train Naive Bayes model\n",
    "        nb = MultinomialNB(alpha=a)\n",
    "        nb.fit(X_tr, y_tr)\n",
    "        y_val_pred = nb.predict(X_val)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        fold_accuracies.append(acc)\n",
    "\n",
    "    # Compute mean accuracy across folds\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    cv_results[a] = mean_acc\n",
    "    print(f\"alpha = {a}, mean CV accuracy = {mean_acc:.4f}\")\n",
    "\n",
    "# Select best alpha\n",
    "best_alpha = max(cv_results, key=cv_results.get)\n",
    "print(\"Best alpha from CV:\", best_alpha, \"with accuracy\", cv_results[best_alpha])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e2b63",
   "metadata": {},
   "source": [
    "## 7. Final model trained on full training set and evaluated on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff459e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.796875\n",
      "Final validation accuracy: 0.6422764227642277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.744     0.780     0.762        41\n",
      "           1      0.585     0.585     0.585        41\n",
      "           2      0.590     0.561     0.575        41\n",
      "\n",
      "    accuracy                          0.642       123\n",
      "   macro avg      0.640     0.642     0.641       123\n",
      "weighted avg      0.640     0.642     0.641       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_nb = MultinomialNB(alpha=best_alpha)\n",
    "final_nb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = final_nb.predict(X_train)\n",
    "y_valid_pred = final_nb.predict(X_valid)\n",
    "\n",
    "print(\"Training accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Final validation accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d75de",
   "metadata": {},
   "source": [
    "## 8. Evaluating on test set\n",
    "### 8.1 Load and preprocess test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4738dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../cleaned_data/test_clean.csv\")\n",
    "\n",
    "# Combine text fields\n",
    "test = combine_text(test)    # uses the same text_cols as train/valid\n",
    "\n",
    "# Clean text\n",
    "test[\"full_text\"] = test[\"full_text\"].apply(clean_text)\n",
    "\n",
    "# Numeric features (same feature_cols as before)\n",
    "X_test_numeric = test[feature_cols].values\n",
    "\n",
    "# Labels\n",
    "y_test = test[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf2367",
   "metadata": {},
   "source": [
    "### 8.2 Build test feature matrix and evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d7f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5952380952380952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.655     0.857     0.742        42\n",
      "           1      0.535     0.548     0.541        42\n",
      "           2      0.571     0.381     0.457        42\n",
      "\n",
      "    accuracy                          0.595       126\n",
      "   macro avg      0.587     0.595     0.580       126\n",
      "weighted avg      0.587     0.595     0.580       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the already-fitted vectorizer\n",
    "X_test_text = vectorizer.transform(test[\"full_text\"])\n",
    "\n",
    "# Combine text + numeric for test\n",
    "X_test = hstack([X_test_text, X_test_numeric])\n",
    "\n",
    "# Predict with final trained Naive Bayes\n",
    "y_test_pred = final_nb.predict(X_test)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
